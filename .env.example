# MeshBot Environment Configuration

# LLM Configuration (OpenAI-compatible endpoints)
# Model format: openai:MODEL_NAME
#
# MODEL_NAME depends on your provider:
#   OpenAI (default): gpt-4o-mini, gpt-4o, gpt-4-turbo
#   OpenRouter: openai/gpt-4o-mini, anthropic/claude-3-5-sonnet-20241022, etc.
#   Ollama: llama3.2, mistral, etc.
#   LM Studio: Use the model name shown in LM Studio
#
# Examples:
#   LLM_MODEL=openai:gpt-4o-mini                          # OpenAI (default)
#   LLM_MODEL=openai:openai/gpt-4o-mini                   # OpenRouter with GPT-4o-mini
#   LLM_MODEL=openai:anthropic/claude-3-5-sonnet-20241022 # OpenRouter with Claude
#   LLM_MODEL=openai:llama3.2                             # Ollama
LLM_MODEL=openai:gpt-4o-mini

# API Key - required for most LLM providers
LLM_API_KEY=your_api_key_here

# Base URL for OpenAI-compatible endpoints (optional)
# Leave unset for OpenAI (default)
# Set this when using alternative providers:
#   OpenRouter: https://openrouter.ai/api/v1
#   Ollama: http://localhost:11434/v1
#   LM Studio: http://localhost:1234/v1
#   Any other OpenAI-compatible endpoint
# LLM_BASE_URL=https://openrouter.ai/api/v1

# Bot Behavior Configuration
# Activation phrase for channel messages (not required for DMs)
ACTIVATION_PHRASE=@bot
# Channel to listen to (0 for General, or specific channel name/number)
LISTEN_CHANNEL=0
# Optional custom prompt file for domain-specific knowledge
# CUSTOM_PROMPT_FILE=prompts/custom.txt

# MeshCore Configuration
MESHCORE_CONNECTION_TYPE=mock
# MESHCORE_PORT=/dev/ttyUSB0
# MESHCORE_HOST=192.168.1.100
# MESHCORE_BAUDRATE=115200
# MESHCORE_DEBUG=false
# MESHCORE_AUTO_RECONNECT=true

# Storage Configuration
MEMORY_PATH=memory_metadata.json

# Memori Configuration (for conversation memory)
# MEMORI_DATABASE_URL=sqlite:///memori_conversations.db
# MEMORI_DATABASE_URL=postgresql://user:pass@localhost/memori

# Logging Configuration
LOG_LEVEL=INFO
# LOG_FILE=meshbot.log